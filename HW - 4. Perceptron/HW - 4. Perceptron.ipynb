{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 401,
   "id": "ea48a446",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "076da5ba",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"><center><h1>Биологический нейрон</h1></center></div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2255b724",
   "metadata": {},
   "source": [
    "**Нейрон** — электрически возбудимая клетка, которая предназначена для приёма извне, обработки, хранения, передачи и вывода вовне информации с помощью электрических и химических сигналов.  \n",
    "  \n",
    "Типичный нейрон состоит из тела клетки, дендритов и одного аксона:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "aa916480",
   "metadata": {},
   "source": [
    "![neuron](images/neuron.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "30244433",
   "metadata": {},
   "source": [
    "Простыми словами можно описать принцип действия нейрона следующим образом:\n",
    "- через дендриты в нейрон поступают сигналы (раздражители)\n",
    "- Если комбинация сигналов превышает пороговый уровень - нейрон \"выстреливает\", т.е. передаёт сигнал дальше через аксон."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2a7ce203",
   "metadata": {},
   "source": [
    "Нейроны могут соединяться один с другим, формируя нервные сети."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5200e275",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"><center><h1>Функции Активации (Activation Functions)</h1></center></div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1d41f55f",
   "metadata": {},
   "source": [
    "Простейшим механизмом активации является **Step activation**, когда перспептрон передаёт на выход значение только в том случае, если сумма взвешенных входящих сигналов больше заданного порога:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ff07a8e1",
   "metadata": {},
   "source": [
    "![step](images/step_activation.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a3b588aa",
   "metadata": {},
   "source": [
    "При всей своей простоте, данная функция активации обладает критическим недостатком: она недифференцируемая.  Как результат, она не позволяет осуществлять процесс обучения персептрона.  \n",
    "  \n",
    "Для того, чтобы исправить это, было разработано множество других функций активаций, таких как:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "baf346ed",
   "metadata": {},
   "source": [
    "![neuron](images/activation_functions.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "40d1d1b0",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\"><center><h1>Задание 1 (2 балла)</h1></center></div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6be49dd4",
   "metadata": {},
   "source": [
    "Напишите класс **ActivationFunction** и его подкласс **Sigmoid**, у которого будет функция `forward`, которая:\n",
    "- будет принимать на вход число и будет сохранять его внутри объекта\n",
    "- будет возвращать результат в соответствии с фукцией $\\sigma(x) = \\frac{1}{1 + e^{-x}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "id": "2a68d43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActivationFunction:\n",
    "    \n",
    "    def __init__(self) -> None:\n",
    "        self.input = None\n",
    "        self.output = None\n",
    "    \n",
    "    def forward(self) -> None:\n",
    "        return \n",
    "\n",
    "\n",
    "class Sigmoid(ActivationFunction):\n",
    "\n",
    "    def forward(self, value: np.ndarray) -> np.ndarray:\n",
    "        self.input = value\n",
    "        self.output = 1.0/(1.0+np.exp(-self.input))\n",
    "        return self.output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "id": "e5f342c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigmoid = Sigmoid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "id": "0ceab0e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.68842773, 0.73079903])"
      ]
     },
     "execution_count": 404,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmoid.forward(np.array([0.79277902, 0.99868032]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8c54ea44",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "78315b25",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "53618f50",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"><center><h1>Персептрон</h1></center></div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "266324a8",
   "metadata": {},
   "source": [
    "**Персептрон** -  математическая модель биологического нейрона, является базовым элементом нейронных сетей:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c63f671b",
   "metadata": {},
   "source": [
    "![neuron](images/perceptron.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "54cc65e4",
   "metadata": {},
   "source": [
    "**Персептрон** состоит из следующих ключевых элементов:\n",
    "- `вход` - отвечает за получение входных значений. Является аналогом дендрита биологического нейрона\n",
    "- `веса` - механизм \"важности\" входных значений. По аналогии с нейроном - это \"толщина\" дендрита\n",
    "- `функция активации` - обрабатывает сумму взвешенных входных сигналов и передаёт результат на выход\n",
    "- `выход` - отвечает за передачу итогового результата. Аналогичен аксону\n",
    "  \n",
    "Практически всегда к входным сигналам также добавляется \"bias\", который всегда = 1.  \n",
    "Это позволяет не привязывать выход персептрона к 0 в случае, если все входные сигналы также равны 0 (как в механизме регрессии)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "057194ee",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\"><center><h1>Задание 2 (4 балла)</h1></center></div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d42423ee",
   "metadata": {},
   "source": [
    "напишите класс **Layer**, у когорого будут следующие входные параметры:\n",
    "- **n_inputs** - количество входящих значений\n",
    "- **n_outputs** - количество исходящих значений (в нашем случае = 1)\n",
    "- **activation** - объект из семейства **ActivationFunction** (в нашем случае - **Sigmoid**)\n",
    "  \n",
    "При своём создании объект класса **Layer** должен также создавать атрибут `weights_`, в ктором будут рандомально инициализированны веса для входящих значений, а также для `bias`\n",
    "\n",
    "Класс **Layer** должен иметь функцию `forward`, принимающую на вход массив *numpy*, и возвращающую результат функции активации (тоже в виде массива).  \n",
    "Также эта функция должна сохранять полученные на вход значения внутри экземпляра"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "id": "04ec3681",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer:\n",
    "\n",
    "    def __init__(self, n_inputs=np.array([1]), n_outputs=np.array([1]), activation=Sigmoid()):\n",
    "        \n",
    "        self.n_inputs = n_inputs\n",
    "        self.n_outputs = n_outputs\n",
    "        self.input = None\n",
    "        self.z = None\n",
    "        self.output = None\n",
    "        self.activation = activation\n",
    "        self.bias = np.random.normal()\n",
    "        self.weights_ = np.random.normal(size=self.n_inputs)\n",
    "\n",
    "    def forward(self, X: np.ndarray) -> np.ndarray:\n",
    "\n",
    "        self.input = X\n",
    "        self.z = []\n",
    "\n",
    "        for example in self.input:\n",
    "            self.z.append(example.dot(self.weights_.T) + self.bias)\n",
    "        \n",
    "        self.z = np.array(self.z)\n",
    "\n",
    "        self.output = self.activation.forward(self.z)\n",
    "\n",
    "        return self.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "id": "84a33bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = Layer(np.array([5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "id": "16759700",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.99999056, 1.        ])"
      ]
     },
     "execution_count": 407,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer.forward(np.array([[1,2,3,4,5],\n",
    "                        [6,7,8,9,10],]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a2100ce8",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2ecfecac",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\"><center><h1>Задание 3 (2 балла)</h1></center></div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "15bcc0dc",
   "metadata": {},
   "source": [
    "напишите класс **LossFunction** и его подкласс **CrossEntropy**, у которого будет функция `loss`, которая будет принимать реальное бинарное значение *y_fact* и вероятность *y_prob* (оба параметра в виде np.array) и будет возвращать результат по формуле:  \n",
    "  \n",
    "$$\n",
    "L = - \\sum (y_{fact} * log(y_{prob}) + (1-y_{fact})*log(1-y_{prob}))\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "id": "40a91107",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LossFunction:\n",
    "    \n",
    "    def __init__(self) -> None:\n",
    "        self.y_fact = None\n",
    "        self.y_prob = None\n",
    "        self.error = None\n",
    "\n",
    "class CrossEntropy(LossFunction):\n",
    "\n",
    "    def loss(self, y_fact: np.ndarray, y_prob: np.ndarray) -> np.ndarray:\n",
    "        \n",
    "        self.y_fact = y_fact\n",
    "        self.y_prob = y_prob\n",
    "        self.error = np.array(-np.mean(self.y_fact * np.log(self.y_prob) + \\\n",
    "                        (1 - self.y_fact) * np.log(1 - self.y_prob)))\n",
    "\n",
    "        return self.error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "id": "248e188c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = CrossEntropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "id": "16949e5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(0.73987037)"
      ]
     },
     "execution_count": 410,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_entropy.loss(np.array([[0, 1]]), np.array([[0.68842773, 0.73079903]]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0724135c",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3adeb1c5",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"><center><h1>Обучение. Forward and Backpropagation</h1></center></div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5305fa49",
   "metadata": {},
   "source": [
    "Процесс обучения персептрона (и в целом нейросети) итеративен и состоит из следующих этапов:\n",
    "- Сперва персептрон инициализируется с рандомальными весами\n",
    "- Осуществляется цикл \"вперёд\":\n",
    "  - Входные значения перемножаются с соответствующими весами и суммируются\n",
    "  - Эта сумма подаётся на функцию активации\n",
    "  - Функция активации возвращает итоговое значение\n",
    "- Итоговое значение сравнивается с ожидаемым и высчитывается ошибка (Loss)\n",
    "- Осуществляется цикл \"назад\":\n",
    "  - при помощи `Chain Rule` рассчитываются частичные производные для всех элементов персептрона\n",
    "  - исходя из заданного коэффициента обучения (`learning rate`, $\\alpha$), веса $w_{i}$ корректируются\n",
    "- Данный цикл повторяется заданное количество раз или до тех пор, пока итоговая ошибка не опустится ниже заданного порогового значения"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "308f269a",
   "metadata": {},
   "source": [
    "![img](images/training.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "561a0181",
   "metadata": {},
   "source": [
    "### <center>Chain Rule</center>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "920cc590",
   "metadata": {},
   "source": [
    "Если нам дана функция $y=f(u)$, где $u = g(x)$, то тогда производная этой функции по $x$ будет равно:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "48de5834",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{dy}{dx} = \\frac{dy}{du}\\frac{du}{dx}\n",
    "$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b0f31ddb",
   "metadata": {},
   "source": [
    "Тогда для того, чтобы понять, насколько изменение весов $w$ влияет на изменение $y$ (т.е. производные $\\frac{dy}{dw_{i}}$), можно вычислить следующие производные:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0d239444",
   "metadata": {},
   "source": [
    "![neuron](images/backpropagation.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6568f1db",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\"><center><h1>Задание 4 (8 баллов)</h1></center></div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7be53a81",
   "metadata": {},
   "source": [
    "Модифицируйте классы **Layer**, **LossFuncton** и **ActivationFunction** таким образом, чтобы можно было рассчитать их частичные производные, и добавьте функцию `back`, позволяющую осуществить backpropagation."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9534b596",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\"><center><h3>Это задание очень сложное, и даже частичное его выполнение будет учитываться</h3></center></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "id": "42c62fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossEntropyWithPrime(CrossEntropy):\n",
    "\n",
    "    def prime(self) -> float:\n",
    "        dLdz = np.mean(-self.y_fact/self.y_prob + (1-self.y_fact)/(1-self.y_prob))\n",
    "        return dLdz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "id": "2e165345",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SigmoidWithPrime(Sigmoid):\n",
    "\n",
    "    def prime(self, dLdz: float) -> float:\n",
    "        dLdz = np.array(dLdz)\n",
    "        dzd = float(self.forward(dLdz) * (1 - self.forward(dLdz)))\n",
    "        return dzd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "id": "98e79191",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron():\n",
    "\n",
    "    def __init__(self,\n",
    "                 n_inputs=np.array([1]),\n",
    "                 activation=SigmoidWithPrime(),\n",
    "                 lossfucn=CrossEntropyWithPrime(),\n",
    "                 lerning_rate = 0.05\n",
    "                 ) -> None:\n",
    "        \n",
    "        self.layer = Layer(n_inputs, activation=activation)\n",
    "        self.lossfucn = lossfucn\n",
    "        self.output = None\n",
    "        self.learning_rate = lerning_rate\n",
    "    \n",
    "    def forward(self, X:np.ndarray) -> np.ndarray:\n",
    "        self.input = X\n",
    "        self.output = self.layer.forward(self.input)\n",
    "        return self.output\n",
    "    \n",
    "    def backward(self, y:np.ndarray) -> None:\n",
    "        self.loss = self.lossfucn.loss(y, self.output)\n",
    "        self.dLdz = self.lossfucn.prime()\n",
    "        self.dzd = self.layer.activation.prime(self.dLdz)\n",
    "\n",
    "        self.dzdw = self.dzd * np.mean(self.input, axis=0)\n",
    "        self.dzdb = self.dzd\n",
    "\n",
    "        self.layer.weights_ += self.learning_rate * self.dzdw\n",
    "        self.layer.bias += self.learning_rate * self.dzdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "id": "9acf4160",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   x1  x2  y\n",
       "0   1   1  1\n",
       "1   1   0  0\n",
       "2   0   1  0\n",
       "3   0   0  1"
      ]
     },
     "execution_count": 427,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(data={'x1': [1,1,0,0],\n",
    "                        'x2': [1,0,1,0],\n",
    "                        'y': [1,0,0,1],})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "id": "7ed4b0b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start weights: [-0.76858328 -0.12795951]\n",
      "start bias: -0.655934622808668\n",
      "losses: 1.744520556662191\n",
      "losses: 1.744118489202627\n",
      "losses: 1.743715536076272\n",
      "losses: 1.7433116937779611\n",
      "losses: 1.74290695878273\n",
      "losses: 1.742501327545668\n",
      "losses: 1.7420947965017757\n",
      "losses: 1.7416873620658144\n",
      "losses: 1.7412790206321611\n",
      "losses: 1.7408697685746568\n",
      "losses: 1.740459602246455\n",
      "losses: 1.7400485179798695\n",
      "losses: 1.739636512086223\n",
      "losses: 1.7392235808556882\n",
      "losses: 1.7388097205571336\n",
      "losses: 1.7383949274379644\n",
      "losses: 1.7379791977239638\n",
      "losses: 1.7375625276191315\n",
      "losses: 1.7371449133055221\n",
      "losses: 1.73672635094308\n",
      "losses: 1.7363068366694743\n",
      "losses: 1.7358863665999347\n",
      "losses: 1.7354649368270778\n",
      "losses: 1.7350425434207426\n",
      "losses: 1.734619182427816\n",
      "losses: 1.7341948498720603\n",
      "losses: 1.7337695417539383\n",
      "losses: 1.7333432540504377\n",
      "losses: 1.7329159827148939\n",
      "losses: 1.7324877236768075\n",
      "losses: 1.7320584728416677\n",
      "losses: 1.7316282260907652\n",
      "losses: 1.731196979281009\n",
      "losses: 1.730764728244742\n",
      "losses: 1.7303314687895504\n",
      "losses: 1.729897196698075\n",
      "losses: 1.7294619077278195\n",
      "losses: 1.7290255976109579\n",
      "losses: 1.7285882620541384\n",
      "losses: 1.7281498967382862\n",
      "losses: 1.7277104973184063\n",
      "losses: 1.7272700594233799\n",
      "losses: 1.7268285786557651\n",
      "losses: 1.7263860505915907\n",
      "losses: 1.7259424707801485\n",
      "losses: 1.7254978347437873\n",
      "losses: 1.7250521379777015\n",
      "losses: 1.7246053759497175\n",
      "losses: 1.7241575441000816\n",
      "losses: 1.723708637841241\n",
      "losses: 1.7232586525576272\n",
      "losses: 1.7228075836054346\n",
      "losses: 1.722355426312397\n",
      "losses: 1.721902175977564\n",
      "losses: 1.721447827871073\n",
      "losses: 1.7209923772339208\n",
      "losses: 1.7205358192777307\n",
      "losses: 1.7200781491845192\n",
      "losses: 1.7196193621064622\n",
      "losses: 1.7191594531656527\n",
      "losses: 1.7186984174538638\n",
      "losses: 1.7182362500323034\n",
      "losses: 1.7177729459313704\n",
      "losses: 1.7173085001504058\n",
      "losses: 1.7168429076574432\n",
      "losses: 1.7163761633889554\n",
      "losses: 1.7159082622496011\n",
      "losses: 1.7154391991119649\n",
      "losses: 1.7149689688162988\n",
      "losses: 1.714497566170259\n",
      "losses: 1.7140249859486405\n",
      "losses: 1.7135512228931087\n",
      "losses: 1.71307627171193\n",
      "losses: 1.7126001270796976\n",
      "losses: 1.7121227836370547\n",
      "losses: 1.7116442359904174\n",
      "losses: 1.7111644787116924\n",
      "losses: 1.7106835063379913\n",
      "losses: 1.7102013133713458\n",
      "losses: 1.7097178942784161\n",
      "losses: 1.7092332434901971\n",
      "losses: 1.7087473554017247\n",
      "losses: 1.7082602243717733\n",
      "losses: 1.7077718447225576\n",
      "losses: 1.7072822107394243\n",
      "losses: 1.7067913166705468\n",
      "losses: 1.7062991567266108\n",
      "losses: 1.7058057250805017\n",
      "losses: 1.7053110158669866\n",
      "losses: 1.7048150231823933\n",
      "losses: 1.7043177410842856\n",
      "losses: 1.7038191635911355\n",
      "losses: 1.7033192846819938\n",
      "losses: 1.7028180982961532\n",
      "losses: 1.7023155983328127\n",
      "losses: 1.7018117786507354\n",
      "losses: 1.7013066330679034\n",
      "losses: 1.7008001553611696\n",
      "losses: 1.700292339265906\n",
      "losses: 1.6997831784756467\n",
      "end weights: [-0.75021785 -0.10959408]\n",
      "end bias: -0.6375691959840867\n"
     ]
    }
   ],
   "source": [
    "perceptron = Perceptron(np.array([2]))\n",
    "\n",
    "print(f'start weights: {perceptron.layer.weights_}')\n",
    "print(f'start bias: {perceptron.layer.bias}')\n",
    "\n",
    "for _ in range(100):\n",
    "\n",
    "    # dff = df.sample(np.random.randint(1, 5), replace=True)\n",
    "    dff = df.iloc[:1, :]\n",
    "    X = dff.iloc[:, :-1].to_numpy()\n",
    "    y = dff.iloc[:, -1:].to_numpy()\n",
    "\n",
    "    perceptron.forward(X)\n",
    "    perceptron.backward(y)\n",
    "    print(f'losses: {perceptron.loss}')\n",
    "\n",
    "print(f'end weights: {perceptron.layer.weights_}')\n",
    "print(f'end bias: {perceptron.layer.bias}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5e5a244e",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "90f00233",
   "metadata": {},
   "source": [
    "# <center>Удачи!</center>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
